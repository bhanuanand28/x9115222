# x9115222

# Repository for CS 591(Automated Software Engineering)

Contributors:-

  Bhanu Anand(bhanuanand28)
  
  Esha Sharma(eshasharma)
  
  Vinay Todalge (vntodalge)

_____________________________________________________________________________________________________________________________

##Coding up the Type 1 , 2 , 3 Comparison Operators and Using them to Compare DE, SA and MWS 

### Running Instructions 
  1. Clone the github repository x9115222 from git@github.com:bhanuanand28/x9115222.git
  2. Navigate to ./x9115222/hw/code/10 
  3. run generic_opt.py
  

###Abstract
In this study , we coded up the Type 1, Type 2 and Type 3 comparison operators and used them to find the final generations for 
Differential Evolution , MaxWalkSat and Simulated Annealing on DTLZ7 with 2 objectives and 10 decisions . We applied the Type 2 
comparison operator to find the loss between the first and the final era generated by a optimizer. Finally , we calculated the loss 
values for 20 runs for each of these optimizers and compared the loss values using Scott-Knott for each of these runs and generated
diagrams which depicted the loss across the 20 generations. The statistical diagrams generated through Scott-Knott showed that 
Differential Evolution optimized DTLZ7 with 2 objectives and 10 decisions the best followed by Simulated Annealing followed by 
MaxWalkSat.  The statistics showed that the central tendency of loss found by Differential Evolution is better then that found by the 
other two optimizers . 

###Introduction and Background
The aim of this study was to study which of the optimizers out of Differential Evolution , Simulated Annealing and MaxWalkSat is 
best to optimize DTLZ7 with 2 objectives and 10 decisions. To study these optimizers we use Type 1 , Type 2 and Type 3 comparison 
operators . To optimize a multiple objective model. different optimizers can be used . These optimizers may or may not find the best 
candidate solution . When we are using stochastic search to optimize a problem , we need some kind of statistical machinery to figure 
out whether or not the given optimizer is the best for the given problem being optimized. In this study our aim is to apply these 
comparison operators and find the best optimizer for a problem. These are the different comparison operators we use in this study : 

###Type 1 , Type 2 , Type 3 Comparison Operators
To compare the functioning of two optimizers , we utilize these three comparison operators : 
  1.  *Type 1 comparison operator*: This operator is used to decide which amongst two candidate solutions is better and generates a
       better solution .If a model has more than one objective, the candidate solution should be better than the other one on each 
       of these objectives. This operator is implemented in the inner most loop of the optimizer and should take the minimum time to
       compute. We can use Boolean or Continuous Domination to decide between two candidates.
  2.   *Type 2 comparison operator* : This operator is used to compare consequent eras generated by an optimizer and decide whether
        or not there is a significant improvement from one era of an optimization solution to the other. This is used for early 
        termination as well. If there is significant improvement between two era we continue with a given iteration else we terminate
        it . We could use hypervolume, spread, loss here for the comparison.
  3.   *Type 3 comparison operator*: This operator is used to decide which of the three optimizers is best for the given problem being 
        optimized. For this we use either of the results generated via the Type 2 operator for this comparison. We can calculate the 
        values generated for a number of runs and compare the results statistically. 

###Implementation 
For this study , we incorporated the Type 1 and Type 2 comparison operators in our Simulated Annealing and MaxWalkSat and Differential
Evolution . We then used the loss values generated between eras of SA, MWS and DE and passed those to Scott Knott and generated 
graphs which we compared to judge performance of the optimizers. This is how these three operators were applied : 
  1.  *Type 1 comparison operator* : This was used to compare two candidates generated through the model in the inner most loop of the
       optimizers and decide which between the two was a better candidate. The comparison is done on each of the objectives of the
       candidates to judge which one is better than the other. For DTLZ7 the objectives grow in the same direction and do not conflict 
       with one another , that is increase in one objective does not imply decrease in the other. Hence we took an aggregation of the 
       objectives giving each of them a weight of 1 and compared this aggregate value .Applying Boolean or Continuous Domonation would
       have been time consuming and is better suited in case a model has objectives which grow in conflicting directions. The type
       one operator should take the minimum time to run because it is run multiple times in a simulator . The aggregation function
       was chosen for this reason .
  2.  *Type 2 comparison operator*: This operator is used to judge the performance of the optimizer between generations. To apply 
       this comparison, we store the first and the final eras generated by an optimizer as lists and apply the a12 test to find the 
       difference between subsequent generations of candidates. This is also used to apply early termination to a run of the optimizer.
       We compared the loss values generated to 0.56 .(why ? quoting STATS.md : According to Vargha and Delaney, a small difference
       between two populations is:when the a12 value is 56% or less ) . If we found that the loss value was over 0.56 then we
       increased the number of iterations for a run by 5 . If not , we reduce this number by 1 . A difference of more than 0.56
       between two populations means that there is a significant change from one era to the next.  
  3.  *Type 3 operator*: This is to compare the final eras generated by different optimizers .For this first we found the loss values
       between the first and the final era produced by an optimizer. We calculated the loss value between these two eras. We then ran
       20 runs of each optimizer so that we had an array of 20 values for each. Next, these arrays were passed in the ScottKnott to 
       generate a statistical diagram. The rdivdemo program creates graphs which show the median, the inter quartile range and
       the 25 %ile , 50 %ile amd 70 % ile values . 

###Results

![alt tag](https://github.com/bhanuanand28/x9115222/blob/master/hw/code/8/ScreenShot/Output.jpg)

It can be observed from the graphs that DE works best on DTLZ 7 with 2 objectives and 10 decisions followed by SA, followed by MWS . 
In the graph we can observe that the rank for DE is the best .Since we are comparing loss values generated between the first and final
generations, this indicates that DE produces the best loss between the first and final generations followed by SA, followed by MWS.
We hence conclude that DE optimizes DTLZ 7 with 2 objectives and 10 decisions the best.

###Conclusions

DE produces the best loss between the first and final generations followed by SA, followed by MWS.


###Threats to Validity 
1. We ran the code only for 20 iterations for each optimizer . Running the code for a larger number of iterations may produce better
and more pronounced difference and better statistics. 
2. We used the loss value between generations to compute the graph . We could have used hypervolume or spread to do this 
comparison as well . The results of loss may be skewed.Basing the results on the hypervolume and the spread as well could lead to 
more reliable results. 
3. We used weights for the objectives in Type 1 operator. These weights were 1 for each objectives in the aggegation function . We 
could change this weight to get better values . In fact this weight could be varied for a range of values and hence checks can be 
performed to see what gives the best results.
4. The inner loop in each optimizer was run just 1000 times , This could have been run more number of times so that the optimizer
could have produced better values for loss and more pronounced difference. This could have exponentially increased the statically 
difference and we could have noted which optimizer was better even more clearly.
5. For early termination , the value of 0.56 seems to be large .We could be terminating from generation to generation prematurely 
based on this value. Decreasing this value could maybe decrease the number of times early termination could have occurred incorrectly.

###Future Work 
1. The code could be run for more number of iterations so that the difference between the loss values for the different optimizers 
is more pronounced. 
2. We could use hypervolume or spread to generate an additional list of values. We can run our Scott Knott on these values as well 
and affirm if the results remain consistent. 
3. The inner loop could be run more than 1000 times so that the loss values are more pronounced . 
4. The weights could have been assigned by selecting a range of different weights and inputting these weights to an optimizer 
which can be used to decide which of these weights work best for the optimizer in quesion.
5. We could change the values of 0.56 and check if the change creates better results . We could also tune the optimizer so that 
the best value is used to decide whether we should do early termination or not. 
6. We could extend this study to Genetic Algorithms and other optimizers and check where DE stands in comparison.

###References
1. https://github.com/txt/mase/blob/master/lessthan.md
2. https://github.com/txt/mase/blob/master/STATS.md

###Acknowledgements
The study uses code for Scott knott , Loss found here: 
1.  https://github.com/txt/mase/blob/master/src/doc/sk.py




