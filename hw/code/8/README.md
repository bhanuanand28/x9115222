# x9115222
##Coding up the Type 1 , 2 , 3 Comparison Operators and Using them to Compare DE, SA and MWS 

#####Group Members:

- Esha Sharma 

- Bhanu Anand

- Vinay Togalde

### Running Instructions 

###Abstract
In this study , we coded up the Type 1, Type 2 and Type 3 comparison operators and used them to find the final generations for 
Differential Evolution , MaxWalkSat and Simulated Annealing on DTLZ7 with 2 objectives and 10 decisions . We applied the Type 2 
comparison operator to find the loss between the first and the final era generated by a optimizer. Finally , we calculated the loss 
values for 20 runs for each of these optimizers and compared the loss values using Scott-Knott for each of these runs and generated
diagrams which depicted the loss across the 20 generations. The statistical diagrams generated through Scott-Knott showed that 
Differential Evolution optimized DTLZ7 with 2 objectives and 10 decisions the best followed by Simulated Annealing followed by 
MaxWalkSat.  The statistics showed that the central tendency of loss found by Differntial Evolution is better then that found by the 
other two optimizers . 

###Introduction and Background
The aim of this study was to study which of the optimizers out of Differential Evolution , Simulated Annealing and MaxWalkSat is best 
to optimize DTLZ7 with 2 objectives and 10 decisions. To study these optimizers we use Type 1 , Type 2 and Type 3 comparison 
operators . To optimize a muliple objective model. different optimizers can be used . These optimizers may or may not find the best 
candidate solution . When we are using stochastic search to optimize a problem , we need some kind of statistical machinery to figure 
out whether or not the given optimizer is the best for the given problem being optimized. In this study our aim is to apply these 
comparison operators and find the best optimizer for a problem. These are the different comparison operators we use in this study : 

###Type 1 , Type 2 , Type 3 Operators
When we are comparing the functioning of two optimisers , we utilise three comparison operators : 
  1.  *Type 1 operator*: This operator is used to decide which amongst two candidates generates a better solution for DTLZ 7 . The 
       DTLZ 7 has 2 objectives and we need to compare if a candidate is better than a second candidtae on both these objectives. The 
       Type 1 operator should take the minimum time to compute . 
  2.   *Type 2 operator* : This operator is used to decide whether ir not there is a significant improvement between two eras generated
        by an optimizer. It is used for early termination as well . If there is significant improvement we continue on with the next
        generation, else we terminate the current generation . 
  3.   *Type 3 operator*: This operator is used to decide which of the three optimizers is best for the given problem being optimized. 

###Implementation 
We applied the Type 1 and Type 2 operators to our code for SA, MWS and DE and compared the loss values between consequent generations
20 times. These values were then compared using Type 3 statistical machinery via Scott Knott and graphs were generated. Thsi is how 
these three operatore were applied : 
  1.  *Type 1 operator* : This was used to compare two candidates generated and decide which one was better . This was done in the inner
       most loop of each optimisers . To compare two candidates we computed the objectives generated for each candidate and aggregated
       them by a simple summation . Since The Type 1 operator should take minimum time to run and also since for DTLZ 7 the objectives 
       do not conflict , doing a summation seemed to be ok .
  2.  *Type 2 operator*: This was used to compare if the set of candidates generation in an era weer better than the candidates 
       generated in the era before. To do this comparison , we used the a12 test and find the loss between the array of value 
       generated in each era with the array of values generate in its consequent era . This was used to apply early termination to the        optimizer. We compared the loss values generated to 0.56 .(quoting STATS :  According to Vargha and Delaney, a small difference        between two populations is:when the a12 value is 56% or less ) . Hence if we found that the loss value was over 0.56 then we          increased the number of iterations by 5 . If not , we reduce them by 1 . A difference of more than 0.56 between two populations        means that there is significant change from one population to the next.  
  3.  *Type 3 operator*: This is to compare the final eras generated by different optimizers . For this we found the loss values from 
       Type 2 operator in 2. 20 times for each optimiser and store this in a list. This list hence contained 20 loss values . We then
       compared the lists generated for the three optimisers by passing it to rdivdemo which genreated Scott knott graphs and the 
       median , the inter quartile range and the 25 %ile , 50 %ile amd 70 % ile values . 

###Results
a=0.56
![alt tag](https://github.com/bhanuanand28/x9115222/blob/master/hw/code/8/ScreenShot/Output.jpg)
a=0.30
![alt tag](https://github.com/bhanuanand28/x9115222/blob/master/hw/code/8/ScreenShot/op2%20.jpg)
a=0.65
![alt tag](https://github.com/bhanuanand28/x9115222/blob/master/hw/code/8/ScreenShot/op3.jpg)

It can be observed from the graphs that DE works best on DTLZ 7 with 2 objectives followeed by SA, followed by MWS . In the graph we can 
observe that Inter Quartile Range for DE is the best . This means that since the rdivdemo was run on loss values between inital and 
final era , This sugests that DE produces the maximum difference between the first and last era. The loss improves from  0.85 to 1.00 
between the 25th and the 75th quartile , which shows that DE produces diverse results . 


###Threats to Validity 
1. We ran the code only for 20 iterations . Running the code for a larger number of iterations may produce better statitics. 
2. We used the loss value between generations to compute the graph . We could have used hypervolume or any other machinery to do this 
comparison as well and based our results on the aggreagation of those results . 
3. We used weights 1 for both objectives in the aggegation function . This could be evaluated with some other weights assigned 
as well. 
4. The inner loop in each optimiser was run just 1000 times , This could have been run more number of times . 
5. The value of 0.56 seemed to be large . 


###Future Work 
1. The code could be run for more number of iterations. 
2. We could use hypervolume etc to generate more than 1 graph and affirm the results across these graphs . 
3. The inner loop could be run more than 1000 times . 
4. The weights could have been assigned by inputting the weights to an optimiser and deciding which produces best optimisation and 
tuning our optimizer based on that . 
5. We could use the value of 0.56 and tune our optimiser to that. 
6. We could tun this for other optimisers like GA and see where DE stands in comparison.



